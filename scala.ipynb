{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://repo1.maven.org/maven2/org/flinkextended/flink-scala-api_2.13/1.18.1_1.2.1/flink-scala-api_2.13-1.18.1_1.2.1.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/flinkextended/flink-scala-api_2.13/1.18.1_1.2.1/flink-scala-api_2.13-1.18.1_1.2.1.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/flinkextended/flink-scala-api_2.13/1.18.1_1.2.1/flink-scala-api_2.13-1.18.1_1.2.1.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/flinkextended/flink-scala-api_2.13/1.18.1_1.2.1/flink-scala-api_2.13-1.18.1_1.2.1-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/flinkextended/flink-scala-api_2.13/1.18.1_1.2.1/flink-scala-api_2.13-1.18.1_1.2.1-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/flinkextended/flink-scala-api_2.13/1.18.1_1.2.1/flink-scala-api_2.13-1.18.1_1.2.1.jar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flinkx.api._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flinkx.api.serializers._\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.flinkextended::flink-scala-api:1.18.1_1.2.1`\n",
    "import $ivy.`org.apache.flink:flink-clients:1.18.1`\n",
    "import $ivy.`org.apache.flink:flink-core:1.18.1`\n",
    "import $ivy.`org.apache.flink:flink-runtime-web:1.18.1`\n",
    "import $ivy.`org.apache.flink:flink-connector-files:1.18.1`\n",
    "import $ivy.`org.apache.flink:flink-table-api-java-bridge:1.18.1`\n",
    "import $ivy.`org.apache.flink:flink-ml-uber-1.17:2.3.0`\n",
    "import $ivy.`org.apache.flink:statefun-flink-core:3.2.0`\n",
    "      \n",
    "import org.apache.flinkx.api._\n",
    "import org.apache.flinkx.api.serializers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.api.common.eventtime.WatermarkStrategy\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.api.common.typeinfo.TypeInformation\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.api.java.typeutils.RowTypeInfo\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.connector.file.src.FileSource\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.connector.file.src.reader.TextLineInputFormat\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.core.fs.Path\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.ml.api.Stage\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.ml.builder.Pipeline\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.ml.classification.logisticregression.LogisticRegression\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.ml.evaluation.binaryclassification.{\n",
       "  BinaryClassificationEvaluator,\n",
       "  BinaryClassificationEvaluatorParams => ClassifierMetric\n",
       "}\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.ml.feature.onehotencoder.OneHotEncoder\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.ml.feature.standardscaler.StandardScaler\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.ml.feature.stringindexer.{StringIndexer, StringIndexerParams}\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.ml.feature.vectorassembler.VectorAssembler\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.table.api._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.types.Row\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flinkx.api.serializers._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.File\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.jdk.CollectionConverters._\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.flink.api.common.eventtime.WatermarkStrategy\n",
    "import org.apache.flink.api.common.typeinfo.TypeInformation\n",
    "import org.apache.flink.api.java.typeutils.RowTypeInfo\n",
    "import org.apache.flink.connector.file.src.FileSource\n",
    "import org.apache.flink.connector.file.src.reader.TextLineInputFormat\n",
    "import org.apache.flink.core.fs.Path\n",
    "import org.apache.flink.ml.api.Stage\n",
    "import org.apache.flink.ml.builder.Pipeline\n",
    "import org.apache.flink.ml.classification.logisticregression.LogisticRegression\n",
    "import org.apache.flink.ml.evaluation.binaryclassification.{\n",
    "  BinaryClassificationEvaluator,\n",
    "  BinaryClassificationEvaluatorParams => ClassifierMetric\n",
    "}\n",
    "import org.apache.flink.ml.feature.onehotencoder.OneHotEncoder\n",
    "import org.apache.flink.ml.feature.standardscaler.StandardScaler\n",
    "import org.apache.flink.ml.feature.stringindexer.{StringIndexer, StringIndexerParams}\n",
    "import org.apache.flink.ml.feature.vectorassembler.VectorAssembler\n",
    "import org.apache.flink.table.api._\n",
    "import org.apache.flink.types.Row\n",
    "\n",
    "import org.apache.flinkx.api.serializers._\n",
    "\n",
    "import java.io.File\n",
    "import scala.jdk.CollectionConverters._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 deprecation (since 2.13.0); re-run with -deprecation for details\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.configuration.Configuration\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.configuration.JobManagerOptions\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.configuration.DeploymentOptions\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.configuration.RestOptions\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.configuration.StateBackendOptions\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.flink.client.deployment.executors.RemoteExecutor\u001b[39m\n",
       "\u001b[36mhost\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"localhost\"\u001b[39m\n",
       "\u001b[36mcfg\u001b[39m: \u001b[32mConfiguration\u001b[39m = {rest.port=8081, taskmanager.memory.network.max=1g, execution.attached=true, jobmanager.rpc.address=localhost, rest.address=localhost, execution.target=remote, jobmanager.rpc.port=8081, state.backend.type=filesystem}\n",
       "\u001b[36mrestPort\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m8081\u001b[39m\n",
       "\u001b[36mres6_16\u001b[39m: \u001b[32mConfiguration\u001b[39m = {rest.port=8081, taskmanager.memory.network.max=1g, execution.attached=true, jobmanager.rpc.address=localhost, rest.address=localhost, execution.target=remote, jobmanager.rpc.port=8081, state.backend.type=filesystem}\n",
       "\u001b[36mlocalCoursierPath\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"/Users/alexeyn/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2\"\u001b[39m\n",
       "\u001b[36mjars\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m\"/Users/alexeyn/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/flink/flink-ml-uber-1.17/2.3.0/flink-ml-uber-1.17-2.3.0.jar\"\u001b[39m,\n",
       "  \u001b[32m\"/Users/alexeyn/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/flink/statefun-flink-core/3.2.0/statefun-flink-core-3.2.0.jar\"\u001b[39m,\n",
       "  \u001b[32m\"/Users/alexeyn/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/scala-lang/scala-library/2.13.15/scala-library-2.13.15.jar\"\u001b[39m,\n",
       "  \u001b[32m\"/Users/alexeyn/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/flinkextended/flink-scala-api_3/1.18.1_1.2.1/flink-scala-api_3-1.18.1_1.2.1.jar\"\u001b[39m\n",
       ")\n",
       "\u001b[36menv\u001b[39m: \u001b[32mStreamExecutionEnvironment\u001b[39m = org.apache.flinkx.api.StreamExecutionEnvironment@739ad48c"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.flink.configuration.Configuration\n",
    "import org.apache.flink.configuration.JobManagerOptions\n",
    "import org.apache.flink.configuration.DeploymentOptions\n",
    "import org.apache.flink.configuration.RestOptions\n",
    "import org.apache.flink.configuration.StateBackendOptions\n",
    "import org.apache.flink.client.deployment.executors.RemoteExecutor\n",
    "\n",
    "val host = \"localhost\"\n",
    "val cfg = new Configuration()\n",
    "cfg.setString(\"taskmanager.memory.network.max\", \"1g\")\n",
    "\n",
    "val restPort = 8081\n",
    "cfg.setString(JobManagerOptions.ADDRESS, host)\n",
    "cfg.setInteger(JobManagerOptions.PORT, restPort)\n",
    "cfg.setString(DeploymentOptions.TARGET, RemoteExecutor.NAME)\n",
    "cfg.setBoolean(DeploymentOptions.ATTACHED, true)\n",
    "cfg.setString(RestOptions.ADDRESS, host)\n",
    "cfg.setInteger(RestOptions.PORT, restPort)\n",
    "cfg.set(StateBackendOptions.STATE_BACKEND, \"filesystem\")\n",
    "val localCoursierPath = s\"${sys.props(\"user.home\")}/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2\"\n",
    "val jars = Array(\n",
    "    s\"$localCoursierPath/org/apache/flink/flink-ml-uber-1.17/2.3.0/flink-ml-uber-1.17-2.3.0.jar\",\n",
    "    s\"$localCoursierPath/org/apache/flink/statefun-flink-core/3.2.0/statefun-flink-core-3.2.0.jar\",\n",
    "    s\"$localCoursierPath/org/scala-lang/scala-library/2.13.15/scala-library-2.13.15.jar\",\n",
    "    s\"$localCoursierPath/org/flinkextended/flink-scala-api_3/1.18.1_1.2.1/flink-scala-api_3-1.18.1_1.2.1.jar\"    \n",
    ")\n",
    "val env = StreamExecutionEnvironment.createRemoteEnvironment(\n",
    "    host,\n",
    "    restPort,\n",
    "    cfg,\n",
    "    jars: _*\n",
    ")\n",
    "env.setParallelism(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mexitedLabel\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"Exited\"\u001b[39m\n",
       "\u001b[36mfilePath\u001b[39m: \u001b[32mPath\u001b[39m = file:/Users/alexeyn/dev/git/flink-ml-sandbox/data/Churn_Modelling.csv\n",
       "\u001b[36msource\u001b[39m: \u001b[32mFileSource\u001b[39m[\u001b[32mString\u001b[39m] = org.apache.flink.connector.file.src.FileSource@58e8cbd4\n",
       "\u001b[36mrawFeatureCols\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m\"CreditScore\"\u001b[39m,\n",
       "  \u001b[32m\"GeographyStr\"\u001b[39m,\n",
       "  \u001b[32m\"GenderStr\"\u001b[39m,\n",
       "  \u001b[32m\"Age\"\u001b[39m,\n",
       "  \u001b[32m\"Tenure\"\u001b[39m,\n",
       "  \u001b[32m\"Balance\"\u001b[39m,\n",
       "  \u001b[32m\"NumOfProducts\"\u001b[39m,\n",
       "  \u001b[32m\"HasCrCard\"\u001b[39m,\n",
       "  \u001b[32m\"IsActiveMember\"\u001b[39m,\n",
       "  \u001b[32m\"EstimatedSalary\"\u001b[39m,\n",
       "  \u001b[32m\"Exited\"\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val exitedLabel = \"Exited\"\n",
    "val filePath =\n",
    "  if (host != \"localhost\")\n",
    "    new Path(\"s3://vvp/artifacts/namespaces/default/Churn_Modelling.csv\")\n",
    "  else Path.fromLocalFile(new File(s\"${new File(\".\").getCanonicalPath}/data/Churn_Modelling.csv\"))\n",
    "\n",
    "val source = FileSource\n",
    "    .forRecordStreamFormat(\n",
    "      new TextLineInputFormat(),\n",
    "      filePath\n",
    "    )\n",
    "    .build()\n",
    "val rawFeatureCols = Array(\n",
    "    \"CreditScore\",\n",
    "    \"GeographyStr\",\n",
    "    \"GenderStr\",\n",
    "    \"Age\",\n",
    "    \"Tenure\",\n",
    "    \"Balance\",\n",
    "    \"NumOfProducts\",\n",
    "    \"HasCrCard\",\n",
    "    \"IsActiveMember\",\n",
    "    \"EstimatedSalary\",\n",
    "    exitedLabel\n",
    "  )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.flink.util.FlinkException",
     "evalue": "Task not serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31morg.apache.flink.util.FlinkException: Task not serializable\u001b[39m",
      "  org.apache.flinkx.api.ClosureCleaner$.ensureSerializable(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m455\u001b[39m)",
      "  org.apache.flinkx.api.ClosureCleaner$.clean(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m428\u001b[39m)",
      "  org.apache.flinkx.api.ClosureCleaner$.clean(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m173\u001b[39m)",
      "  org.apache.flinkx.api.ClosureCleaner$.scalaClean(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m177\u001b[39m)",
      "  org.apache.flinkx.api.StreamExecutionEnvironment.scalaClean(\u001b[32mStreamExecutionEnvironment.scala\u001b[39m:\u001b[32m743\u001b[39m)",
      "  org.apache.flinkx.api.DataStream.clean(\u001b[32mDataStream.scala\u001b[39m:\u001b[32m855\u001b[39m)",
      "  org.apache.flinkx.api.DataStream.map(\u001b[32mDataStream.scala\u001b[39m:\u001b[32m518\u001b[39m)",
      "  ammonite.$sess.cell9$Helper.<init>(\u001b[32mcell9.sc\u001b[39m:\u001b[32m17\u001b[39m)",
      "  ammonite.$sess.cell9$.<clinit>(\u001b[32mcell9.sc\u001b[39m:\u001b[32m7\u001b[39m)",
      "\u001b[31mjava.io.NotSerializableException: org.apache.flinkx.api.StreamExecutionEnvironment\u001b[39m",
      "  java.io.ObjectOutputStream.writeObject0(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1175\u001b[39m)",
      "  java.io.ObjectOutputStream.defaultWriteFields(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1543\u001b[39m)",
      "  java.io.ObjectOutputStream.writeSerialData(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1500\u001b[39m)",
      "  java.io.ObjectOutputStream.writeOrdinaryObject(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1423\u001b[39m)",
      "  java.io.ObjectOutputStream.writeObject0(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1169\u001b[39m)",
      "  java.io.ObjectOutputStream.defaultWriteFields(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1543\u001b[39m)",
      "  java.io.ObjectOutputStream.writeSerialData(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1500\u001b[39m)",
      "  java.io.ObjectOutputStream.writeOrdinaryObject(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1423\u001b[39m)",
      "  java.io.ObjectOutputStream.writeObject0(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1169\u001b[39m)",
      "  java.io.ObjectOutputStream.defaultWriteFields(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1543\u001b[39m)",
      "  java.io.ObjectOutputStream.writeSerialData(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1500\u001b[39m)",
      "  java.io.ObjectOutputStream.writeOrdinaryObject(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1423\u001b[39m)",
      "  java.io.ObjectOutputStream.writeObject0(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1169\u001b[39m)",
      "  java.io.ObjectOutputStream.writeArray(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1369\u001b[39m)",
      "  java.io.ObjectOutputStream.writeObject0(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1165\u001b[39m)",
      "  java.io.ObjectOutputStream.defaultWriteFields(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1543\u001b[39m)",
      "  java.io.ObjectOutputStream.writeSerialData(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1500\u001b[39m)",
      "  java.io.ObjectOutputStream.writeOrdinaryObject(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1423\u001b[39m)",
      "  java.io.ObjectOutputStream.writeObject0(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m1169\u001b[39m)",
      "  java.io.ObjectOutputStream.writeObject(\u001b[32mObjectOutputStream.java\u001b[39m:\u001b[32m345\u001b[39m)",
      "  org.apache.flinkx.api.ClosureCleaner$.ensureSerializable(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m453\u001b[39m)",
      "  org.apache.flinkx.api.ClosureCleaner$.clean(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m428\u001b[39m)",
      "  org.apache.flinkx.api.ClosureCleaner$.clean(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m173\u001b[39m)",
      "  org.apache.flinkx.api.ClosureCleaner$.scalaClean(\u001b[32mClosureCleaner.scala\u001b[39m:\u001b[32m177\u001b[39m)",
      "  org.apache.flinkx.api.StreamExecutionEnvironment.scalaClean(\u001b[32mStreamExecutionEnvironment.scala\u001b[39m:\u001b[32m743\u001b[39m)",
      "  org.apache.flinkx.api.DataStream.clean(\u001b[32mDataStream.scala\u001b[39m:\u001b[32m855\u001b[39m)",
      "  org.apache.flinkx.api.DataStream.map(\u001b[32mDataStream.scala\u001b[39m:\u001b[32m518\u001b[39m)",
      "  ammonite.$sess.cell9$Helper.<init>(\u001b[32mcell9.sc\u001b[39m:\u001b[32m17\u001b[39m)",
      "  ammonite.$sess.cell9$.<clinit>(\u001b[32mcell9.sc\u001b[39m:\u001b[32m7\u001b[39m)"
     ]
    }
   ],
   "source": [
    "import org.apache.flinkx.api.serializers._\n",
    "import org.apache.flink.ml.linalg.DenseVector\n",
    "import org.apache.flink.ml.linalg.typeinfo.DenseVectorTypeInfo\n",
    "\n",
    "implicit val rowTypes: RowTypeInfo = new RowTypeInfo(\n",
    "    doubleInfo +: (Array[TypeInformation[?]](stringInfo, stringInfo) ++ Array.fill(8)(doubleInfo)),\n",
    "    rawFeatureCols\n",
    "  )\n",
    "\n",
    "implicit val denseVectorTypeInfo: TypeInformation[DenseVector] =\n",
    "    DenseVectorTypeInfo.INSTANCE\n",
    "\n",
    "val skipColCount = 3\n",
    "val csvStream = env\n",
    "  .fromSource(source, WatermarkStrategy.noWatermarks(), \"trainingData\")\n",
    "  .filter(l => !l.startsWith(\"#\"))\n",
    "  .map { l =>        \n",
    "    val row = l.split(\",\").slice(skipColCount, skipColCount + rawFeatureCols.length)\n",
    "    Row.of(\n",
    "      row(0).toDouble,\n",
    "      row(1),\n",
    "      row(2),\n",
    "      row(3).toDouble,\n",
    "      row(4).toDouble,\n",
    "      row(5).toDouble,\n",
    "      row(6).toDouble,\n",
    "      row(7).toDouble,\n",
    "      row(8).toDouble,\n",
    "      row(9).toDouble,\n",
    "      row(10).toDouble\n",
    "    )\n",
    "  }.setParallelism(3) // it is tunned based on the current CSV data volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala (2.13)",
   "language": "scala",
   "name": "scala213"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
